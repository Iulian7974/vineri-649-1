import streamlit as st
import pandas as pd
import json
import sqlite3
import os

st.set_page_config(page_title="Loto 6/49 Offline", layout="centered")
st.title("üìä Loto 6/49 - Vizualizare Offline")

# === Frecven»õƒÉ din JSON ===
st.subheader("üî¢ Frecven»õa numerelor (all time)")
try:
    with open("loto_frequency.json") as f:
        freq = json.load(f)
    df_freq = pd.DataFrame({"NumƒÉr": freq["labels"], "Frecven»õƒÉ": freq["values"]})
    df_freq = df_freq.sort_values("Frecven»õƒÉ", ascending=False)
    st.bar_chart(df_freq.set_index("NumƒÉr"))
except Exception as e:
    st.warning(f"Nu s-a putut √ÆncƒÉrca frecven»õa: {e}")

# === Microtrend ultimele 20 ===
st.subheader("üìà Microtrend pe ultimele 20 extrageri")
try:
    with open("microtrend_20.json") as f:
        trends = json.load(f)
    numar_ales = st.number_input("Alege un numƒÉr (1-49)", min_value=1, max_value=49, value=17)
    trend = next((item for item in trends if item["number"] == numar_ales), None)
    if trend:
        df_trend = pd.DataFrame(trend["trend"])
        st.line_chart(df_trend.set_index("x"))
except Exception as e:
    st.warning(f"Eroare la trend: {e}")

# === Co-apari»õii ===
st.subheader("üîó Matrice co-apari»õii")
try:
    with open("coappear_matrix.json") as f:
        matrix = json.load(f)
    df_matrix = pd.DataFrame(matrix["matrix"], index=matrix["labels"], columns=matrix["labels"])
    st.dataframe(df_matrix)
except Exception as e:
    st.warning(f"Eroare la matrice: {e}")

# === Filtrare localƒÉ din baza de date ===
st.subheader("üéØ Filtrare extrageri locale")
an = st.selectbox("Alege anul", ["2023", "2024", "2025"])
numar = st.number_input("NumƒÉr de urmƒÉrit", min_value=1, max_value=49, value=17, key="numar_urmarit")

try:
    with sqlite3.connect("loto_data.db") as conn:
        query = f"""
            SELECT * FROM loto_draws
            WHERE strftime('%Y', Data) = '{an}'
            AND ({' OR '.join([f'"Nr.{i}" = {numar}' for i in range(1, 7)])})
            ORDER BY Data DESC
        """
        df_filtrat = pd.read_sql(query, conn)
        st.dataframe(df_filtrat)
except Exception as e:
    st.warning(f"Nu s-au putut √ÆncƒÉrca extragerile. Baza de date va fi creatƒÉ la prima √ÆncƒÉrcare a unui fi»ôier Excel.")


# === Predic»õii generate automat ===
st.subheader("üîÆ Cele mai bune 5 predic»õii (din top 20 frecvente)")
try:
    with open("predictii_top5.json") as f:
        pred_data = json.load(f)
    st.markdown(f"**Top 20 numere frecvente:** {sorted(pred_data['top20'])}")
    for i, pred in enumerate(pred_data["predictii"], 1):
        st.markdown(f"**Predic»õia {i}:** üéØ {sorted(pred)}")
except Exception as e:
    st.warning(f"Nu s-au putut √ÆncƒÉrca predic»õiile: {e}")


# === Predic»õie ML pe baza celor mai recente 20 de extrageri ===
st.subheader("üî¨ Predic»õie ML (ultimele 20 extrageri)")
try:
    with open("predictie_ml_rf_20draws.json") as f:
        ml20 = json.load(f)
    st.success(f"üìà Predic»õie ML: {ml20['predictie_model_20draws']}")
except Exception as e:
    st.warning(f"Predic»õia nu este disponibilƒÉ: {e}")


# === Simulare inteligentƒÉ: Predic»õii pe baza scorurilor de probabilitate ===
st.subheader("üéØ Simulare inteligentƒÉ: predic»õii bazate pe probabilitate")
try:
    with open("simulare_predictii_interactive.json") as f:
        simulare = json.load(f)
    st.image("heatmap_probabilitati_20.png", caption="üìä Heatmap scoruri pe ultimele 20 extrageri", use_container_width=True)
    st.markdown(f"**üîù Top 20 scoruri:** {simulare['top20_probabilitati']}")
    st.markdown("**üé∞ Combina»õii sugerate (aleator din top 20):**")
    for idx, combo in enumerate(simulare['combinatii_sugerate'], 1):
        st.markdown(f"{idx}. {combo}")
except Exception as e:
    st.warning(f"Simularea nu este disponibilƒÉ: {e}")


# === Actualizare bazƒÉ de date din fi»ôier Excel nou ===
st.subheader("üì§ ActualizeazƒÉ extragerile din fi»ôier Excel")
uploaded_file = st.file_uploader("√éncarcƒÉ un fi»ôier Excel cu extrageri noi", type=["xlsx"])

if uploaded_file is not None:
    try:
        new_df = pd.read_excel(uploaded_file)
        draw_cols = ['Nr.1', 'Nr.2', 'Nr.3', 'Nr.4', 'Nr.5', 'Nr.6']
        new_df['Data'] = pd.to_datetime(new_df['Data'], errors='coerce')
        new_df[draw_cols] = new_df[draw_cols].map(int) # .map() is the modern replacement for .applymap()
        new_df = new_df.dropna(subset=['Data'])

        with sqlite3.connect("loto_data.db") as conn:
            try:
                # Check if table exists, if not, create an empty DataFrame
                existing_df = pd.read_sql("SELECT * FROM loto_draws", conn)
            except pd.io.sql.DatabaseError:
                existing_df = pd.DataFrame(columns=['Data'] + draw_cols)

            combined_df = pd.concat([existing_df, new_df], ignore_index=True).drop_duplicates(subset=["Data"] + draw_cols)
            combined_df.to_sql("loto_draws", conn, if_exists="replace", index=False)
            st.success(f"‚úÖ {len(new_df)} extrageri noi au fost adƒÉugate. Total actual: {len(combined_df)}.")
            
            # Recalculare »ôi salvare doar dacƒÉ actualizarea a avut succes
            # === Recalculare automatƒÉ a predic»õiei ML dupƒÉ actualizare ===
            try:
                recent_df = combined_df.sort_values("Data", ascending=False).head(20)
                if len(recent_df) >= 20:
                    X_train = recent_df[draw_cols]
                    y_preds = []

                    from sklearn.ensemble import RandomForestClassifier
                    for col in draw_cols:
                        model = RandomForestClassifier(n_estimators=100, random_state=42)
                        model.fit(X_train.drop(columns=[col]), X_train[col])
                        pred = model.predict([X_train.drop(columns=[col]).iloc[-1]])[0]
                        y_preds.append(int(pred))

                    with open("predictie_ml_rf_20draws.json", "w") as f:
                        json.dump({"predictie_model_20draws": y_preds}, f)

                    st.success(f"üîÅ Predic»õia ML a fost recalculatƒÉ: {y_preds}")

                    # === Salvare istoric predic»õii ML ===
                    try:
                        istoric_path = "istoric_predictii_ml.json"
                        if os.path.exists(istoric_path):
                            with open(istoric_path, "r") as f:
                                istoric = json.load(f)
                        else:
                            istoric = []

                        istoric.append({
                            "data": str(pd.Timestamp.now().date()),
                            "predictie": y_preds
                        })

                        with open(istoric_path, "w") as f:
                            json.dump(istoric, f, indent=2)

                        st.info("üìö Predic»õia ML a fost salvatƒÉ √Æn istoric.")
                    except Exception as e_hist:
                        st.warning(f"Eroare la salvarea √Æn istoric: {e_hist}")
                else:
                    st.warning("Nu existƒÉ suficiente date (minim 20 de extrageri) pentru a recalcula predic»õia ML.")
            except Exception as e_ml:
                st.warning(f"Nu s-a putut recalcula predic»õia ML: {e_ml}")

    except Exception as e_main:
        st.error(f"Eroare la procesarea fi»ôierului: {e_main}")